# AUTOGENERATED! DO NOT EDIT! File to edit: ../10_core.ipynb.

# %% ../10_core.ipynb 2
from __future__ import annotations

# %% auto 0
__all__ = ['Telescope']

# %% ../10_core.ipynb 3
from fastcore.basics import patch

import logging
import requests
from requests import session

import configparser
import diskcache
from bs4 import BeautifulSoup
import json
import time
import os, tempfile, shutil
from os import path
from os.path import expanduser

from zipfile import ZipFile, BadZipFile
from io import StringIO, BytesIO
from tqdm.auto import tqdm

# %% ../10_core.ipynb 4
from ouscope.util import cleanup

# %% ../10_core.ipynb 5
class Telescope:
    '''
    Main telescope website API class.
    '''
    
    url='https://www.telescope.org/'
    cameratypes={
        'constellation':'1',
        'galaxy':       '2',
        'cluster':      '3',
        'planet':'5',
        'coast':'6',
        'pirate':'7',
    }

    REQUESTSTATUS_TEXTS={
        1: "New",
        2: "New, allocated",
        3: "Waiting",
        4: "In progress",
        5: "Reallocate",
        6: "Waiting again",
        7: "Complete on site",
        8: "Complete",
        9: "Hold",
        10: "Frozen",
        20: "Expired",
        21: "Expired w/CJobs",
        22: "Cancelled",
        23: "Cancelled w/CJobs",
        24: "Invalid",
        25: "Never rises",
        26: "Other error",
    }
    
    def __init__(self, user, passwd, cache='.cache/jobs'):
        self.s=None
        self.user=user
        self.passwd=passwd
        self.tout=60
        self.retry=15
        self.login()
        self.cache=cache


# %% ../10_core.ipynb 6
@patch
def login(self: Telescope):
    '''
    Login into the telescope site using credentials initialised in the constructor.
    Start and store persistent session with the website.
    '''
    log = logging.getLogger(__name__)
    payload = {'action': 'login',
               'username': self.user,
               'password': self.passwd,
               'stayloggedin': 'true'}
    log.debug('Get session ...')
    self.s=session()
    log.debug('Logging in ...')
    self.s.post(self.url+'login.php', data=payload)

# %% ../10_core.ipynb 7
@patch
def logout(self: Telescope):
    '''
    Logout and close the session. The stored session data are removed.  
    '''
    if self.s is None :
        self.s.post(self.url+'logout.php')
        self.s=None

# %% ../10_core.ipynb 11
@patch
def get_user_requests(self: Telescope, 
                      folder: int =1,    # Id of the listed folder. Inbox=1.
                      sort : str ='rid', # Name of the sorting colum: 'rid', 'object' or 'completion'
                      ) -> list(dict):   # List of dictionaries representing the requests.
    '''
    Get all user requests from folder (Inbox=1 by default),
    sorted by sort column ('rid' by default). 
    Possible sort columns are: 'rid', 'object', 'completion'
    The data is returned as a list of dictionaries.
    '''

    #fetch first batch        
    params={
        'limit': 100,
        'sort': sort,
        'folderid': folder}

    rq = self.s.post(self.url+"api-user.php", {'module': "request-manager", 
                                               'request': "1-get-list-own",
                                               'params' : json.dumps(params)})
    res=[]
    dat=json.loads(rq.content)
    total=int(dat['data']['totalRequests'])
    res+=dat['data']['requests']

    # Fetch the rest
    params['limit']=total-len(res)
    params['startAfterRow']=len(res)
    rq = self.s.post(self.url+"api-user.php", {'module': "request-manager", 
                                               'request': "1-get-list-own",
                                               'params' : json.dumps(params)})

    dat=json.loads(rq.content)
    total=int(dat['data']['totalRequests'])
    res+=dat['data']['requests']
    return res

# %% ../10_core.ipynb 13
@patch
def get_user_folders(self: Telescope):
    '''
    Get all user folders. Returns list of dictionaries.
    '''
    rq = self.s.post(self.url+"api-user.php", {'module': "request-manager", 
                                               'request': "0-get-my-folders"})
    return json.loads(rq.content)['data']

# %% ../10_core.ipynb 15
@patch
def get_obs_list(self: Telescope, t=None, dt=1, filtertype='', camera='', hour=16, minute=0, verb=False):
    '''Get the dt days of observations taken no later then time in t.

        ### Input
        
        t  - end time in seconds from the epoch
            (as returned by time.time())
        dt - number of days, default to 1
        filtertype - filter by type of filter used
        camera - filter by the camera/telescope used

        ### Output
        
        Returns a list of JobIDs (int) for the observations.

    '''

    assert(self.s is not None)

    if t is None :
        t=time.time()-time.timezone


    st=time.gmtime(t-86400*dt)
    et=time.gmtime(t)

    d=st.tm_mday
    m=st.tm_mon
    y=st.tm_year
    de=et.tm_mday
    me=et.tm_mon
    ye=et.tm_year

    log = logging.getLogger(__name__)
    log.debug('%d/%d/%d -> %d/%d/%d', d,m,y,de,me,ye)

    try :
        telescope=self.cameratypes[camera.lower()]
    except KeyError:
        telescope=''

    searchdat = {
        'sort1':'completetime',
        'sort1order':'desc',
        'searchearliestcom[]':[d, m, y, str(hour),str(minute)],
        'searchlatestcom[]':  [de,me,ye,str(hour),str(minute)],
        'searchstatus[]':['1'],
        'resultsperpage':'1000',
        'searchfilter':filtertype,
        'searchtelescope':telescope,
        'submit':'Go'
    }

    headers = {'Content-Type': 'application/x-www-form-urlencoded'}


    request = self.s.post(self.url+'v3job-search-query.php',
                     data=searchdat, headers=headers)
    soup = BeautifulSoup(request.text,'lxml')

    if verb:
        for h in soup.findAll('h3'):
            if 'Parameters' in h.text:
                print('Params:')
                for l in h.find_next_sibling().get_text(strip=True, separator='\n').splitlines():
                    print(l)
            elif 'Results' in h.text:
                p = h.find_next_sibling()
                if 'jobs' in p.text:
                    print('Results:')
                    for l in h.find_next_sibling().get_text(strip=True, separator='\n').splitlines():
                        print(l)
    
    jlst=[]
    for l in soup.findAll('tr'):
        try :
            a=l.find('a').get('href')
        except AttributeError :
            continue
        jid=a.rfind('jid')
        if jid>0 :
            jid=a[jid+4:].split('&')[0]
            jlst.append(int(jid))
    return jlst

# %% ../10_core.ipynb 17
@patch
def get_job(self: Telescope, jid=None):
    '''Get a job data for a given JID'''

    assert(jid is not None)
    assert(self.s is not None)

    log = logging.getLogger(__name__)
    log.debug(jid)

    obs={}
    obs['jid']=jid
    rq=self.s.post(self.url+('v3cjob-view.php?jid=%d' % jid))
    soup = BeautifulSoup(rq.text, 'lxml')
    for l in soup.findAll('tr'):
        log.debug(cleanup(l.text))
        txt=''
        for f in l.findAll('td'):
            if txt.find('Object Type') >= 0:
                obs['type']=f.text
            if txt.find('Object ID') >= 0:
                obs['oid']=f.text
            if txt.find('Telescope Type Name') >= 0:
                obs['tele']=f.text
            if txt.find('Filter Type') >= 0:
                obs['filter']=f.text
            if txt.find('Exposure Time') >= 0:
                obs['exp']=f.text
            if txt.find('Completion Time') >= 0:
                t=f.text.split()
                obs['completion']=t[3:6]+[t[6][1:]]+[t[7][:-1]]
            if txt.find('Status') >= 0:
                obs['status']= (f.text == 'Success')

            txt=f.text
    log.info('%(jid)d [%(tele)s, %(filter)s, %(status)s]: %(type)s %(oid)s %(exp)s', obs)

    return obs

# %% ../10_core.ipynb 19
@patch
def download_obs(self: Telescope, obs=None, directory='.', cube=True, pbar=False):
    '''Download the raw observation obs (obtained from get_job) into 3D fits
    file named jid.fits located in the directory (current by default).
    Alternatively, when the cube=False the file will be a zip of 3 fits files.
    The name of the file (without directory) is returned.
    
    The zip API got dropped from telescope.org and it stoped working. 
    
    '''

    assert(obs is not None)
    assert(self.s is not None)

    if not cube:
        print('The zip output is no longer supported!')
        return None
    
    chunksize = 1024
    rq=self.s.get(self.url+
                  ('v3image-download%s.php?jid=%d' %
                    ('' if cube else '-layers', obs['jid'])),
                  stream=True)
    
    size = int(rq.headers.get('Content-Length', 0))
    tq = None
    fn = ('%(jid)d.' % obs) + ('fits' if cube else 'zip')
    if pbar :
        tq = tqdm(desc=fn,       
                  total=size,       
                  unit="B",       
                  unit_scale=True,        
                  leave=True,       
                  miniters=1)
    
    with open(path.join(directory, fn), 'wb') as fd:
        for chunk in rq.iter_content(chunksize):
            if chunk:
                fd.write(chunk)
                if tq :
                    tq.update(len(chunk))
    if tq :
        tq.close()
    return fn


# %% ../10_core.ipynb 21
@patch
def get_obs(self: Telescope, obs=None, cube=True, recurse=True, pbar=False):
    '''Get the raw observation obs (obtained from get_job) into zip
    file-like object. The function returns ZipFile structure of the
    downloaded data.'''

    assert(obs is not None)
    assert(self.s is not None)

    log = logging.getLogger(__name__)

    fn = ('%(jid)d.' % obs) + ('fits' if cube else 'zip')
    fp = path.join(self.cache,fn[0],fn[1],fn)
    if not path.isfile(fp) :
        log.info('Getting %s from server', fp)
        os.makedirs(path.dirname(fp), exist_ok=True)
        self.download_obs(obs,path.dirname(fp),cube=cube,pbar=pbar)
    else :
        log.info('Getting %s from cache', fp)
    content = open(fp,'rb')
    try :
        return content if cube else ZipFile(content)
    except BadZipFile :
        # Probably corrupted download. Try again once.
        content.close()
        os.remove(fp)
        if recurse :
            return self.get_obs(obs, cube, False)
        else :
            return None


# %% ../10_core.ipynb 23
@patch
def download_obs_processed(self: Telescope, obs=None, directory='.', cube=False, pbar=False):
    '''Download the raw observation obs (obtained from get_job) into zip
    file named job_jid.zip located in the directory (current by default).
    Alternatively, when the cube=True the file will be a 3D fits file.
    The name of the file (without directory) is returned.'''

    assert(obs is not None)
    assert(self.s is not None)

    log = logging.getLogger(__name__)

    fn=None

    tout=self.tout
    tq = None
    chunksize = 1024
 
    while tout > 0 :
        rq=self.s.get(self.url+
                      ('imageengine-request.php?jid=%d&type=%d' %
                        (obs['jid'], 1 if cube else 3 )))

        soup = BeautifulSoup(rq.text, 'lxml')
        dlif=soup.find('iframe')

        try :
            dl=dlif.get('src')
            rq=self.s.get(self.url+dl,stream=True)
            size = int(rq.headers.get('Content-Length', 0))
            fn = ('art_%(jid)d.' % obs) + ('fits' if cube else 'zip')

            if pbar :
                tq = tqdm(desc=fn,       
                          total=size,       
                          unit="B",       
                          unit_scale=True,        
                          leave=True,       
                          miniters=1)

            with open(path.join(directory, fn), 'wb') as fd:
                for chunk in rq.iter_content(chunksize):
                    fd.write(chunk)
                    if tq :
                        tq.update(len(chunk))
                    
            if tq: 
                tq.close()
            return fn
        except AttributeError :
            tout-=self.retry
            log.warning('No data. Sleep for %ds ...'%self.retry)
            time.sleep(self.retry)

    return None



# %% ../10_core.ipynb 25
@patch
def get_obs_processed(self: Telescope, obs=None, cube=False):
    '''Get the raw observation obs (obtained from get_job) into zip
    file-like object. The function returns ZipFile structure of the
    downloaded data.'''

    assert(obs is not None)
    assert(self.s is not None)
    log = logging.getLogger(__name__)

    tout=self.tout
       
    while tout > 0 :
        rq=self.s.get(self.url+
                      ('imageengine-request.php?jid=%d&type=%d' %
                        (obs['jid'], 1 if cube else 3 )))

        soup = BeautifulSoup(rq.text,'lxml')
        dlif=soup.find('iframe')
        try :
            dl=dlif.get('src')
            rq=self.s.get(self.url+dl,stream=True)
            return BytesIO(rq.content) if cube else ZipFile(BytesIO(rq.content))

        except AttributeError :
            tout-=self.retry
            log.warning('No data. Sleep for %ds ...'%self.retry)
            time.sleep(self.retry)

    return None

